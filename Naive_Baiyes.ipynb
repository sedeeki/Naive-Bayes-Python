{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_3_DM_NB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j1GHFsExrdO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e0b93095-bc79-4b04-c42c-03b1df8138cf"
      },
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import math\n",
        "import nltk\n",
        "import string\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzD-Uck1yVpG"
      },
      "source": [
        "with ZipFile('large_movie_review_dataset.zip','r') as zipOb:\n",
        "  zipOb.extractall('dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftAjG0u1xn8D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d74d5f9c-4867-4f69-eda5-a92ac0b6706f"
      },
      "source": [
        "root = 'dataset'\n",
        "reviews = [] # document text\n",
        "classifier = [] #positve or negative\n",
        "for subdir, dirs, files in os.walk(root):\n",
        "  for file in files:\n",
        "    f = open(os.path.join(subdir,file), 'r')\n",
        "    txt = f.read()\n",
        "    if (subdir.endswith('pos')):\n",
        "      classifier.append('pos')\n",
        "    elif (subdir.endswith('neg')):\n",
        "      classifier.append('neg')\n",
        "    reviews.append(txt) #remove_stopwords(txt)  \n",
        "print (reviews[3],\"\\n\",classifier[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I have copy of this on VHS, I think they (The television networks) should play this every year for the next twenty years. So that we don't forget what was and that we remember not to do the same mistakes again. Like putting some people in the director's chair, where they don't belong. This movie Rappin' is like a vaudevillian musical, for those who can't sing, or act. This movie is as much fun as trying to teach the 'blind' to drive a city bus.<br /><br />John Hood, (Peebles) has just got out of prison and he's headed back to the old neighborhood. In serving time for an all-to-nice crime of necessity, of course. John heads back onto the old street and is greeted by kids dogs old ladies and his peer homeys as they dance and sing all along the way.<br /><br />I would recommend this if I was sentimental, or if in truth someone was smoking medicinal pot prescribed by a doctor for glaucoma. Either way this is a poorly directed, scripted, acted and even produced (I never thought I'd sat that) satire of ghetto life with the 'Hood'. Although, I think the redeeming part of the story, through the wannabe gang fight sequences and the dance numbers, his friends care about their neighbors and want to save the ghetto from being torn down and cleaned up. <br /><br />Forget Sonny spoon, Mario could have won an Oscar for that in comparison to this Rap. Oh well if you find yourself wanting to laugh yourself silly and three-quarters embarrassed, be sure to drink first. <br /><br />And please, watch responsibly. (No stars, better luck next time!) \n",
            " neg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlNsEC88XtBV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "945ff92c-ed81-4a17-9c30-bf6934dc28b9"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df['Reviews'] = reviews\n",
        "df['Classifier'] = classifier\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Classifier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Solid comedy entertainment, with musical inter...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The only good part about this film is the beau...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From the beginning of the movie I had a feelin...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I have copy of this on VHS, I think they (The ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'm not a huge Freddy Krueger fan,but that doe...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I really enjoyed this movie. It was edgy witho...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>One of the most magnificent movies ever made. ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I found this flick enjoyable and involving to ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>The subject matter of this film is potentially...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>Watched this on KQED, with Frank Baxter commen...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Reviews Classifier\n",
              "0      Solid comedy entertainment, with musical inter...        neg\n",
              "1      The only good part about this film is the beau...        neg\n",
              "2      From the beginning of the movie I had a feelin...        neg\n",
              "3      I have copy of this on VHS, I think they (The ...        neg\n",
              "4      I'm not a huge Freddy Krueger fan,but that doe...        neg\n",
              "...                                                  ...        ...\n",
              "49995  I really enjoyed this movie. It was edgy witho...        pos\n",
              "49996  One of the most magnificent movies ever made. ...        pos\n",
              "49997  I found this flick enjoyable and involving to ...        pos\n",
              "49998  The subject matter of this film is potentially...        pos\n",
              "49999  Watched this on KQED, with Frank Baxter commen...        pos\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m-9T5HVYnnN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "447f98db-1b26-4158-e17d-c8b9dee24c53"
      },
      "source": [
        "\n",
        "## To split the data between test and train values\n",
        "##\n",
        "##\n",
        "def split_data(percent=0.80):           #training data is 'percent' times of total\n",
        "    values= np.array(df)\n",
        "    np.random.shuffle(values)\n",
        "    trainingDataLen = math.floor(len(values)*percent)\n",
        "    #print (trainingDataLen)\n",
        "\n",
        "    #print (data_given.iloc[trainingDataLen])\n",
        "    trainingValues = values[:trainingDataLen, :]\n",
        "    #testDataLen = len(self.values) - trainingDataLen\n",
        "    testValues = values[trainingDataLen: , :]\n",
        "    testDataLen = len(testValues)\n",
        "    #print (testDataLen)\n",
        "    return trainingValues,testValues\n",
        "trainValues, testValues = split_data(0.75)  # 25pc Test and 75pc Train\n",
        "print (np.shape(trainValues),np.shape(testValues))    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37500, 2) (12500, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzU1f9C7BJTF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9bf9728e-217f-45eb-830c-4b96841a8b1c"
      },
      "source": [
        "def remove_stopwords(text_tokens):\n",
        "  #txt = txt.split()\n",
        "  text_tokens = word_tokenize(text_tokens)\n",
        "  tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
        "  return ' '.join(tokens_without_sw)\n",
        "remove_stopwords(str(trainValues[1001,0]))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A brings new wife home former wife died `` accident '' . His new wife released institution VERY rich ! All sudden starts hearing noises seeing skulls place . Is going crazy first wife coming back dead ? < br / > < br / > You 've probably guessed ending I n't spell . I saw many times Saturday afternoon TV kid . Back , I liked I WAS young . Seeing I realize bad . It 's horribly acted , badly written , dull ( even hour ) huge cast FIVE people ( director ) ! Still good things . < br / > < br / > The music kinda creepy setting huge empty house pond nearby nicely atmospheric . There scary moments ( I jumped little saw first skull ) somewhat effective ending . All 's definitely NOT good movie ... total disaster either . It small cult following . I give 2. < br / > < br / > Also try avoid Elite DVD Drive-in edition ( 's paired `` Attack Giant Leeches '' ) . It 's TERRIBLE shape jumps scratches . It n't even look bad TV !\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jth_pk10QVoE"
      },
      "source": [
        "\n",
        "def tokenizer(txt):\n",
        "  #f = open(txtfile,'r')\n",
        "  #txtfile = f.read()\n",
        "  txt = txt.translate(str.maketrans('', '', string.punctuation))#remove punctuation\n",
        "  txtlist = word_tokenize(txt)\n",
        "  txtlist_lower = [word.lower() for word in txtlist]\n",
        "  counts = Counter(txtlist_lower)\n",
        "  return counts\n",
        "\n",
        "\n",
        "#function to count total frequency of a dictionary\n",
        "def countTotalFreq(d):\n",
        "  count = 0\n",
        "  for i in d:\n",
        "    count += d[i]\n",
        "  return count  \n",
        "\n",
        "def countNegativesPositives(classifier):\n",
        " \n",
        "  classifier = list(classifier[:,1]) #positives and negatives\n",
        "  counts = Counter(classifier)\n",
        "  #print (counts)\n",
        "  return counts\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK_wVQ1ZgAu9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "760a2de7-fb24-4cca-ecb7-94aba7ddedec"
      },
      "source": [
        "\n",
        "class naiveBayes:\n",
        "\n",
        "  def __init__(self,testData,trainData):\n",
        "    self.testData = testData\n",
        "    self.trainData = trainData\n",
        "    #np.random.shuffle(trainData) \n",
        "    #np.random.shuffle(testData)\n",
        "  \n",
        "  def combineData(self,b=False):\n",
        "    s = \"\"\n",
        "    sPos =\"\"\n",
        "    sNeg =\"\"\n",
        "    if (b):\n",
        "      for i in self.trainData:\n",
        "        s+=i[0]\n",
        "        if i[1] == 'neg':\n",
        "          sNeg+=\" \"\n",
        "          sNeg+=i[0] \n",
        "        elif i[1] == 'pos': \n",
        "          sPos+=\" \"\n",
        "          sPos+=i[0]\n",
        "      return tokenizer(s),tokenizer(sNeg),tokenizer(sPos)\n",
        "    else:\n",
        "      for i in self.testData:\n",
        "        s+=i[0]\n",
        "        if i[1] == 'neg':\n",
        "          sNeg+=\" \"\n",
        "          sNeg+=i[0] \n",
        "        elif i[1] == 'pos': \n",
        "          sPos+=\" \"\n",
        "          sPos+=i[0] \n",
        "      return tokenizer(s),tokenizer(sNeg),tokenizer(sPos)\n",
        "  \n",
        "  def train(self):\n",
        "    posnegCount = countNegativesPositives(self.trainData)  \n",
        "    d = {}\n",
        "    totalCount = posnegCount['pos'] + posnegCount['neg']\n",
        "    #priors for both classes\n",
        "    print (posnegCount['pos'],posnegCount['neg'])\n",
        "    print (\"length of posnegCount: \",len(posnegCount))\n",
        "    priorsPos = np.log (float(posnegCount['pos']) / float(totalCount) )\n",
        "    priorsNeg = np.log(float(posnegCount['neg']) / float(totalCount))\n",
        "    \n",
        "    #dictionaries containing all the\n",
        "    # freqs and words in all the training documents\n",
        "    combinedDict,negDict,posDict = self.combineData(True)\n",
        "    print (\"Combined all bro\")\n",
        "\n",
        "    # Probabilities\n",
        "    probPos = {}\n",
        "    probNeg = {}\n",
        "    lenPosDict = countTotalFreq(posDict)\n",
        "    lenNegDict = countTotalFreq(negDict)\n",
        "    \n",
        "    j = 0\n",
        "    print (\"|V| positive \",len(posDict))\n",
        "    print (\"count(positive) \", lenPosDict)\n",
        "    print (\"|V| negative \",len(negDict))\n",
        "    print(\"count(negative) \", lenNegDict)\n",
        "    for i in posDict:\n",
        "      probPos[i] = np.log( (posDict[i] + 1.0) / (float(lenPosDict)  + float(len(posDict)) ))\n",
        "      \n",
        "      #probPos.append( posDict[i] + 1.0 / float(countTotalFreq(posDict))  + float(len(posDict)))\n",
        "    print (\"pos prob done\")\n",
        "    for i in negDict:\n",
        "      probNeg[i] = np.log ((negDict[i] + 1.0) / ( float(lenNegDict) + len(negDict)   ) )\n",
        "  \n",
        "\n",
        "    return priorsPos,priorsNeg,probPos,probNeg\n",
        "    #for w in combinedDict:\n",
        "      #print(combinedDict[w])\n",
        "    #return combinedDict  \n",
        "    #print(len(combinedDict),len(negDict),len(posDict))\n",
        "  def trainIt(self):\n",
        "    self.priorsPos,self.priorsNeg,self.probPos,self.probNeg = self.train()\n",
        "  \n",
        "  def predict(self,txt):\n",
        "    #priorsPos,priorsNeg,probPos,probNeg = self.train()\n",
        "    txt = tokenizer(txt)\n",
        "    pveProb = 1\n",
        "    nveProb = 1\n",
        "    #print (self.priorsNeg,self.priorsPos)\n",
        "      #check if belongs to positive\n",
        "    for i in txt:\n",
        "      if(i in self.probPos):\n",
        "        pveProb += ( self.priorsPos *  self.probPos[i]**txt[i] )\n",
        "      if(i in self.probNeg):\n",
        "        nveProb +=  ( self.priorsNeg * self.probNeg[i]**txt[i] )\n",
        "    \n",
        "    if (nveProb>pveProb):\n",
        "      return \"neg\"\n",
        "    else:\n",
        "      return \"pos\"\n",
        "  def evaluate(self):\n",
        "    res = [self.predict(i[0]) for i in self.testData]\n",
        "    num = float(len(self.testData[:,1] == res ))\n",
        "    den = len(self.testData)\n",
        "    return num/den  \n",
        "\n",
        "\n",
        "myAlgo = naiveBayes(testValues,trainValues)\n",
        "#combinedDict,negDict,posDict = myAlgo.combineData(True)\n",
        "myAlgo.trainIt()\n",
        "#print(super_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18756 18744\n",
            "length of posnegCount:  2\n",
            "Combined all bro\n",
            "|V| positive  104636\n",
            "count(positive)  4360335\n",
            "|V| negative  100182\n",
            "count(negative)  4283439\n",
            "pos prob done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN_W7XKOu5Le",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67d09d8a-04b4-43f2-f5d7-4b096cac47fa"
      },
      "source": [
        "print(myAlgo.evaluate())\n",
        "#myAlgo.predict(\"I did not like it but most people were favorable of this movie\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}